{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4e6c47-e781-4352-a794-9c6a75dfffe6",
   "metadata": {},
   "source": [
    "## 위로봇 오복이 모델 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da49e66-8312-4efe-b69e-ea0246cf9998",
   "metadata": {},
   "source": [
    "### Base Model Load\n",
    " - 출처 : https://github.com/snunlp/KR-SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74cf3c0-4f04-48cd-b174-12c06c3b7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('j5ng/et5-sentence-comfort')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df58cc7-bd7e-4844-9d27-67fef45d599b",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0fe91b-f136-4337-8421-4e7b3e0ad93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"../resources/comfort_datasets.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19eaca1-e42c-4f13-aafb-f7f0b647e41d",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36efcc8-2ee4-4574-abf0-795033560121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|                                         | 0/1078 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Batches: 100%|██████████████████████████████| 1078/1078 [05:24<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = model.encode(\n",
    "    df['user'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a2d8b59-1dd8-4bb1-a3ac-5e5d29e5c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 자살할래\n",
      "<입력 문장과 유사한 5 개의 문장>\n",
      "1: 자살할까 :하루만 더 버티자고 마음먹고 일주일만 버티자고 마음먹고 한 달을 더 버티자 다짐하고 나면 모든 일이 잘 풀릴 거예요. 나쁜 생각하지 마시고 힘내세요 (유사도: 0.8999)\n",
      "2: 자살할래. :선생님이 죽는다면 슬퍼할 사람이 너무 많을 거예요. 그렇다고 다른 사람들때문에 선생님이 살아야 하는 건 아니예요. 선생님 자신을 위해서 최선을 다해 살면 하루하루 소소한 일상이 행복을 가져다 줄 거예요. (유사도: 0.8653)\n",
      "3: 자살하고싶어 :죽고 싶었던 하루였지만 그래도 살아줘서 고마워요. 오늘 하루도 고생 많았어요. 잘 견뎌내줬네요. 내일은 더 나은 삶이 기다리고 있을 거예요. 분명 작은 조그마한 변화가 있을 거예요. 토닥토닥 고생했고, 오늘 잠들 때는 좋은 꿈 행복한 꿈꿨으면 좋겠습니다 (유사도: 0.8273)\n",
      "4: 자살하고싶어 :삶을 살다 보면 큰 행복은 아니어도 소소한 행복 같은 게 올 거예요. 그러니까 그런 생각 가지지 말고 살아주세요. 선생님 힘내세요. (유사도: 0.8273)\n",
      "5: 자살하기로 했어 :잠시 한 번만 생각해봐요. 내가 죽으면 슬퍼할 사람들을요… 분명히 이 고통 또한 지나갈 거예요… 고통이 지나가기 전까지 제가 옆에서 지켜드릴게요. (유사도: 0.8236)\n"
     ]
    }
   ],
   "source": [
    "query = \"자살할래\"\n",
    "query_embedding = model.encode(query, normalize_embeddings=True)\n",
    "\n",
    "top_k = min(5, len(df))\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, query_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"<입력 문장과 유사한 {top_k} 개의 문장>\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {df.loc[int(idx)]['user']} :{df.loc[int(idx)]['answer']} {'(유사도: {:.4f})'.format(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95d6c3-8319-4d51-b656-0d343f688cb5",
   "metadata": {},
   "source": [
    "### Sbert 모델 ONNX 양자화(quantization) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fec1a-bde8-4153-bfd6-eb0e5c2fdd25",
   "metadata": {},
   "source": [
    "#### Onnx 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca490278-b707-4d67-b8a2-e735a0d246c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5EncoderModel, AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = \"j5ng/et5-sentence-comfort\"\n",
    "\n",
    "T5EncoderModel._keys_to_ignore_on_load_unexpected = [\"decoder.*\"]\n",
    "model = T5EncoderModel.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "encoder = pipeline(\n",
    "    \"feature-extraction\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_tensors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d652f672-1a19-4ce9-89ae-f2504c24dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.0.1\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers.convert_graph_to_onnx as onnx_convert\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "onnx_convert.convert_pytorch(encoder, opset=17, output=Path(\"encoder.onnx\"),\n",
    "\tuse_external_format=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16681da3-53e5-4b3b-8d5e-f34886f2702e",
   "metadata": {},
   "source": [
    "#### Onnx 모델 Uint8(0~255)로 가중치(Weight) 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc76b028-9833-49b3-8233-eda961aea488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/encoder/block.0/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.0/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.1/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.1/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.2/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.2/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.3/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.3/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.4/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.4/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.5/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.5/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.6/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.6/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.7/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.7/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.8/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.8/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.9/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.9/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.10/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.10/layer.0/SelfAttention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.11/layer.0/SelfAttention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/block.11/layer.0/SelfAttention/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "quantize_dynamic(\"encoder.onnx\", \"encoder.onnx_uint8.onnx\", \n",
    "                 weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edd762-e53c-41c0-8313-fb7ee0413c2b",
   "metadata": {},
   "source": [
    "### Onnx 모델로 \"user\"질문 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf01d5b-2910-4b60-a8cd-3f98e3a4736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_PATH = \"j5ng/et5-sentence-comfort\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "sess = InferenceSession(\"../models/onnx/encoder.onnx_uint8.onnx\" , providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f49f175-9ac5-42d6-8e6b-b55a6f157a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask, input_mask_expanded, sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a46406-06b6-448c-aa7b-c3b5bb8d6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_query(query: str, normalize_embeddings=False) -> np.ndarray:\n",
    "    # user turn sequence to query embedding\n",
    "    model_inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                   for k, v in model_inputs.items()}\n",
    "    sequence = sess.run(None, inputs_onnx)\n",
    "    query_embedding = mean_pooling(\n",
    "        sequence, inputs_onnx[\"attention_mask\"])[0][0]\n",
    "\n",
    "    if normalize_embeddings:\n",
    "        query_embedding = query_embedding / \\\n",
    "            np.linalg.norm(query_embedding)\n",
    "\n",
    "    return query_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4aedf41-1acf-473b-b748-2197e29acdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 34477/34477 [14:07<00:00, 40.67it/s]\n"
     ]
    }
   ],
   "source": [
    "onnx_embeddings = [ embedding_query(sen, normalize_embeddings=True) for sen in tqdm(df['user'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148e6e9d-07c6-47f4-a602-d014008c1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"onnx_embeddings.npy\",onnx_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99759726-11f2-45bd-8fa7-e19f592f2a39",
   "metadata": {},
   "source": [
    "### Faiss 벡터 양자화(PQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaefdf89-1fd7-41e5-9599-80742042a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe8029f-5e4a-4a13-911a-4e47fa1dc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./onnx_embeddings.npy\")\n",
    "\n",
    "# IndexPQ 생성\n",
    "d = embeddings.shape[1]\n",
    "nbits = 8  # 각 부분벡터의 비트 수\n",
    "m = 768  # 분할 수\n",
    "\n",
    "# dot product 거리 측정을 사용하는 벡터 인코더\n",
    "index = faiss.IndexPQ(d, m, nbits, faiss.METRIC_INNER_PRODUCT)  # PQ 색인 생성\n",
    "index.train(embeddings)  # 색인 훈련\n",
    "index.add(embeddings)  # 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a95605-ff69-4af8-9cbc-8062ab0d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 저장\n",
    "faiss.write_index(index, \"faiss_onnx_uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945e22a-8928-45a8-a443-2121a5f44914",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc672623-d030-4da1-8eac-db25a9a526c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(query: str):\n",
    "    embedding = np.expand_dims(embedding_query(query, normalize_embeddings=True), axis=0)\n",
    "    D, I = index.search(embedding, 5)\n",
    "    return df.loc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a2e2b3f-0649-4172-8abc-5edbb684d405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30948, 30935, 30927, 29123, 30947]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply(\"짝사랑 포기하는 방법\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cfb0526d-9686-4241-b2fe-2f4aca07d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRF:\n",
    "    def __init__(self):\n",
    "        self.EMBED_WEIGHT: int = 0.6\n",
    "        self.KEYWORD_WEIGHT: int = 0.4\n",
    "    \n",
    "    def get_ranking(self, query1_ids, query2_ids):\n",
    "        # 중복 없는 모든 값들을 구합니다.\n",
    "        all_values = list(set(query1_ids + query2_ids))\n",
    "\n",
    "        # 결과를 저장할 딕셔너리를 초기화합니다.\n",
    "        ranking = {}\n",
    "\n",
    "        # 모든 값을 순회하면서 해당 값의 순위를 구합니다.\n",
    "        for value in all_values:\n",
    "            rank1 = result1.index(value) + 1 if value in result1 else None\n",
    "            rank2 = result2.index(value) + 1 if value in result2 else None\n",
    "            ranking[value] = [rank1, rank2]\n",
    "\n",
    "        return ranking\n",
    "    \n",
    "    def reciprocal_rank(self, rank):\n",
    "        \"\"\"주어진 순위에 대한 Reciprocal Rank를 계산하는 함수\"\"\"\n",
    "        try:\n",
    "            return 1 / rank\n",
    "        except TypeError:\n",
    "            return 0.0\n",
    "        \n",
    "    def get_rrf_scores(self, query1_ids, query2_ids):\n",
    "        \n",
    "        ranking = get_ranking(query1_ids, query2_ids)\n",
    "        \n",
    "        ids = []\n",
    "        scores = []\n",
    "\n",
    "        for key in ranking.keys():\n",
    "            # 각 검색 시스템의 순위\n",
    "            embed_rank = ranking[key][0]\n",
    "            keyword_rank = ranking[key][1]\n",
    "\n",
    "            # 각 검색 시스템의 Reciprocal Rank 계산\n",
    "            embed_rr = self.reciprocal_rank(embed_rank)\n",
    "            keyword_rr = self.reciprocal_rank(keyword_rank)\n",
    "\n",
    "            # 가중치가 적용된 Reciprocal Rank 계산\n",
    "            rrf = (self.EMBED_WEIGHT * embed_rr) + (self.KEYWORD_WEIGHT * keyword_rr)\n",
    "\n",
    "            scores.append(rrf)\n",
    "            ids.append(key)\n",
    "\n",
    "        sorted_scores = sorted(scores, reverse=True)\n",
    "        sorted_ids = [key for _, key in sorted(zip(scores, ranking.keys()), reverse=True)]\n",
    "        return {\"ids\": sorted_ids, \"scores\": sorted_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "252507b1-d85a-4f0a-9d48-7b0110af0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = [30948, 30935, 30927, 29123, 30947]\n",
    "result2 = [30935, 30948, 30949, 30947, 29123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "254e66c3-e18e-4594-a096-0f3d6a8ccf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf = RRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2dd3ca5b-3425-4475-9e3e-4c392d73bc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [30948, 30935, 29123, 30947, 30927, 30949],\n",
       " 'scores': [0.8, 0.7, 0.23, 0.22, 0.19999999999999998, 0.13333333333333333]}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrf.get_rrf_scores(result1, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607c451-db09-44c5-bc26-c1ef0bd14a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

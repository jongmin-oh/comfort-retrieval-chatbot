{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4e6c47-e781-4352-a794-9c6a75dfffe6",
   "metadata": {},
   "source": [
    "## 위로봇 오복이 모델 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da49e66-8312-4efe-b69e-ea0246cf9998",
   "metadata": {},
   "source": [
    "### Base Model Load\n",
    " - 출처 : https://github.com/snunlp/KR-SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74cf3c0-4f04-48cd-b174-12c06c3b7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df58cc7-bd7e-4844-9d27-67fef45d599b",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0fe91b-f136-4337-8421-4e7b3e0ad93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../resource/오복이_답변.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19eaca1-e42c-4f13-aafb-f7f0b647e41d",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36efcc8-2ee4-4574-abf0-795033560121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████| 397/397 [01:21<00:00,  4.85it/s]\n"
     ]
    }
   ],
   "source": [
    "query_embeddings = model.encode(\n",
    "    df['user'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a2d8b59-1dd8-4bb1-a3ac-5e5d29e5c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 아 지금 내 삶이 너무 힘들다 쉬고 싶어\n",
      "<입력 문장과 유사한 5 개의 문장>\n",
      "1: 지금까지 열심히 달려왔으니 잠시 쉬는것도 좋아요 (유사도: 0.7515)\n",
      "2: 삶을 포기하는 건 해결책이 될 수 없어요. 선생님의 삶은 소중합니다. 제가 도와드릴테니 조금만 더 힘을 내주세요. (유사도: 0.7336)\n",
      "3: 저도 가끔은 아무것도 안하고 그냥 누워있고 싶어요~ 하지만 그럴수는 없으니깐.. 그래도 쉴때만큼은 푹 쉬세요!! (유사도: 0.7191)\n",
      "4: 지금 뭐하고 있는데 심심해요? (유사도: 0.7154)\n",
      "5: 저도 심심한데! 뭐 재밌는 거 없을까요? (유사도: 0.7154)\n"
     ]
    }
   ],
   "source": [
    "query = \"아 지금 내 삶이 너무 힘들다 쉬고 싶어\"\n",
    "query_embedding = model.encode(query, normalize_embeddings=True)\n",
    "\n",
    "top_k = min(5, len(df))\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, query_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "print(f\"입력 문장: {query}\")\n",
    "print(f\"<입력 문장과 유사한 {top_k} 개의 문장>\")\n",
    "\n",
    "for i, (score, idx) in enumerate(zip(top_results[0], top_results[1])):\n",
    "    print(f\"{i+1}: {df.loc[int(idx)]['answer']} {'(유사도: {:.4f})'.format(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95d6c3-8319-4d51-b656-0d343f688cb5",
   "metadata": {},
   "source": [
    "### Sbert 모델 ONNX 양자화(quantization) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fec1a-bde8-4153-bfd6-eb0e5c2fdd25",
   "metadata": {},
   "source": [
    "#### Onnx 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d652f672-1a19-4ce9-89ae-f2504c24dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/convert_graph_to_onnx.py:379: FutureWarning: The `transformers.convert_graph_to_onnx` package is deprecated and will be removed in version 5 of Transformers\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 11\n",
      "Loading pipeline (model: snunlp/KR-SBERT-V40K-klueNLI-augSTS, tokenizer: snunlp/KR-SBERT-V40K-klueNLI-augSTS)\n",
      "Creating folder onnx_models\n",
      "Using framework PyTorch: 2.0.1\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_1 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "convert(framework=\"pt\", model=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\", output=Path(\"onnx_models/sbert-model.onnx\"), opset=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16681da3-53e5-4b3b-8d5e-f34886f2702e",
   "metadata": {},
   "source": [
    "#### Onnx 모델 Uint8(0~255)로 가중치(Weight) 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc76b028-9833-49b3-8233-eda961aea488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layer.11/attention/self/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quantize_dynamic(\"onnx_models/sbert-model.onnx\", \"onnx_models/sbert-model_uint8.onnx\", \n",
    "                 weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edd762-e53c-41c0-8313-fb7ee0413c2b",
   "metadata": {},
   "source": [
    "### Onnx 모델로 \"user\"질문 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf01d5b-2910-4b60-a8cd-3f98e3a4736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "sess = InferenceSession(\"./onnx_models/sbert-model_uint8.onnx\" , providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f49f175-9ac5-42d6-8e6b-b55a6f157a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask, input_mask_expanded, sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a46406-06b6-448c-aa7b-c3b5bb8d6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_query(query: str, normalize_embeddings=False) -> np.ndarray:\n",
    "    # user turn sequence to query embedding\n",
    "    model_inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                   for k, v in model_inputs.items()}\n",
    "    sequence = sess.run(None, inputs_onnx)\n",
    "    query_embedding = mean_pooling(\n",
    "        sequence, inputs_onnx[\"attention_mask\"])[0][0]\n",
    "\n",
    "    if normalize_embeddings:\n",
    "        query_embedding = query_embedding / \\\n",
    "            np.linalg.norm(query_embedding)\n",
    "\n",
    "    return query_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4aedf41-1acf-473b-b748-2197e29acdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 12701/12701 [03:18<00:00, 64.12it/s]\n"
     ]
    }
   ],
   "source": [
    "onnx_embeddings = [ embedding_query(sen, normalize_embeddings=True) for sen in tqdm(df['user'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "148e6e9d-07c6-47f4-a602-d014008c1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"onnx_embeddings.npy\",onnx_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99759726-11f2-45bd-8fa7-e19f592f2a39",
   "metadata": {},
   "source": [
    "### Faiss 벡터 양자화(PQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaefdf89-1fd7-41e5-9599-80742042a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fe8029f-5e4a-4a13-911a-4e47fa1dc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./onnx_embeddings.npy\")\n",
    "\n",
    "# IndexPQ 생성\n",
    "d = embeddings.shape[1]\n",
    "nbits = 8  # 각 부분벡터의 비트 수\n",
    "m = 768  # 분할 수\n",
    "\n",
    "# dot product 거리 측정을 사용하는 벡터 인코더\n",
    "index = faiss.IndexPQ(d, m, nbits, faiss.METRIC_INNER_PRODUCT)  # PQ 색인 생성\n",
    "index.train(embeddings)  # 색인 훈련\n",
    "index.add(embeddings)  # 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a95605-ff69-4af8-9cbc-8062ab0d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 저장\n",
    "faiss.write_index(index, \"faiss_onnx_uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945e22a-8928-45a8-a443-2121a5f44914",
   "metadata": {},
   "source": [
    "### 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc672623-d030-4da1-8eac-db25a9a526c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(query: str):\n",
    "    embedding = np.expand_dims(embedding_query(query, normalize_embeddings=True), axis=0)\n",
    "    D, I = index.search(embedding, 5)\n",
    "    return df.loc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02d9226f-bcff-4236-9b91-9314e5dcc11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>answer</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11317</th>\n",
       "      <td>여자친구와 헤어진지 8일</td>\n",
       "      <td>아직도 많이 힘드시군요. 시간이 약이라는 말이 있듯이 조금만 더 힘내시길 바랍니다.</td>\n",
       "      <td>연애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11271</th>\n",
       "      <td>여자친구가 왜 나랑 헤어졌는지 아직도 모르겠어</td>\n",
       "      <td>이유를 모른다면 그 이유를 찾기 위해 노력해야 해요. 곰곰히 생각해보세요 여자친구는...</td>\n",
       "      <td>연애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11210</th>\n",
       "      <td>여자친구 무시했다가 이별 당했습니다.</td>\n",
       "      <td>연애는 서로 존중하는 마음이 있어야 오래갈 수 있습니다. 이번 기회를 통해 자신의 ...</td>\n",
       "      <td>연애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>어젯밤. 헤어졌던 여자친구에게 전화가 왔어.</td>\n",
       "      <td>그 친구는 아직도 선생님을 잊지 못하고 있나봐요. 다시 만날 의향이 있다면, 이번에...</td>\n",
       "      <td>연애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12624</th>\n",
       "      <td>헤어진 여자친구를 다시 만나고 싶어</td>\n",
       "      <td>정말 좋은 사람이라고 후회할 것 같다면 늦지 않게 연락해보세요.</td>\n",
       "      <td>연애</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user  \\\n",
       "11317              여자친구와 헤어진지 8일   \n",
       "11271  여자친구가 왜 나랑 헤어졌는지 아직도 모르겠어   \n",
       "11210       여자친구 무시했다가 이별 당했습니다.   \n",
       "11139   어젯밤. 헤어졌던 여자친구에게 전화가 왔어.   \n",
       "12624        헤어진 여자친구를 다시 만나고 싶어   \n",
       "\n",
       "                                                  answer class  \n",
       "11317     아직도 많이 힘드시군요. 시간이 약이라는 말이 있듯이 조금만 더 힘내시길 바랍니다.    연애  \n",
       "11271  이유를 모른다면 그 이유를 찾기 위해 노력해야 해요. 곰곰히 생각해보세요 여자친구는...    연애  \n",
       "11210  연애는 서로 존중하는 마음이 있어야 오래갈 수 있습니다. 이번 기회를 통해 자신의 ...    연애  \n",
       "11139  그 친구는 아직도 선생님을 잊지 못하고 있나봐요. 다시 만날 의향이 있다면, 이번에...    연애  \n",
       "12624                정말 좋은 사람이라고 후회할 것 같다면 늦지 않게 연락해보세요.    연애  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply(\"어제 여자친구랑 헤어졌다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee413030-13b0-4ed5-be5b-dc8c7e95b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b8c4b4b-1afb-4818-9935-e0b3221734a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"../resources/comfort_datasets.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "181b9a3b-dcf8-49e5-a644-b83e159a25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_PATH = \"j5ng/et5-sentence-comfort\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "sess = InferenceSession(\"./encoder.onnx_uint8.onnx\" , providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e663ea95-a8eb-4602-a0d4-d317e85dbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    model_output = torch.from_numpy(model_output[0])\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output\n",
    "    attention_mask = torch.from_numpy(attention_mask)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size())\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask, input_mask_expanded, sum_mask\n",
    "\n",
    "def embedding_query(query: str, normalize_embeddings=False) -> np.ndarray:\n",
    "    # user turn sequence to query embedding\n",
    "    model_inputs = tokenizer(query, return_tensors=\"pt\")\n",
    "    inputs_onnx = {k: v.cpu().detach().numpy()\n",
    "                   for k, v in model_inputs.items()}\n",
    "    sequence = sess.run(None, inputs_onnx)\n",
    "    query_embedding = mean_pooling(\n",
    "        sequence, inputs_onnx[\"attention_mask\"])[0][0]\n",
    "\n",
    "    if normalize_embeddings:\n",
    "        query_embedding = query_embedding / \\\n",
    "            np.linalg.norm(query_embedding)\n",
    "\n",
    "    return query_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44f8924d-8c93-441f-876f-4585496fc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.read_index(\"./faiss_onnx_uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3e884e4-7fa6-487a-9def-b37cd7c0baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply(query: str):\n",
    "    embedding = np.expand_dims(embedding_query(query, normalize_embeddings=True), axis=0)\n",
    "    D, I = index.search(embedding, 5)\n",
    "    return df.loc[I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a13ac89d-e6c5-4cb0-89fc-48c31684e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from kiwipiepy.utils import Stopwords\n",
    "import pickle\n",
    "\n",
    "stopwords = Stopwords()\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = kiwi.tokenize(text, stopwords=stopwords)\n",
    "    return [ (pos.form, pos.tag) for pos in tokens]\n",
    "\n",
    "bm25result = pickle.load(open('bm25result', 'rb'))\n",
    "    \n",
    "def bm25_chatbot_response(query, n=5):\n",
    "    tokenized_query = tokenize(query)\n",
    "    scores = bm25result.get_scores(tokenized_query)\n",
    "    top_5_indices = np.argsort(scores)[-5:]\n",
    "    res = df.loc[top_5_indices[::-1]]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7650864-3e78-48cf-96d0-b989892aa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRF:\n",
    "    def __init__(self):\n",
    "        self.EMBED_WEIGHT: int = 0.6\n",
    "        self.KEYWORD_WEIGHT: int = 0.4\n",
    "    \n",
    "    def get_ranking(self, query1_ids, query2_ids):\n",
    "        # 중복 없는 모든 값들을 구합니다.\n",
    "        all_values = list(set(query1_ids + query2_ids))\n",
    "\n",
    "        # 결과를 저장할 딕셔너리를 초기화합니다.\n",
    "        ranking = {}\n",
    "\n",
    "        # 모든 값을 순회하면서 해당 값의 순위를 구합니다.\n",
    "        for value in all_values:\n",
    "            rank1 = query1_ids.index(value) + 1 if value in query1_ids else None\n",
    "            rank2 = query2_ids.index(value) + 1 if value in query2_ids else None\n",
    "            ranking[value] = [rank1, rank2]\n",
    "\n",
    "        return ranking\n",
    "    \n",
    "    def reciprocal_rank(self, rank):\n",
    "        \"\"\"주어진 순위에 대한 Reciprocal Rank를 계산하는 함수\"\"\"\n",
    "        try:\n",
    "            return 1 / rank\n",
    "        except TypeError:\n",
    "            return 0.0\n",
    "        \n",
    "    def get_rrf_scores(self, query1_ids, query2_ids):\n",
    "        \n",
    "        ranking = self.get_ranking(query1_ids, query2_ids)\n",
    "        \n",
    "        ids = []\n",
    "        scores = []\n",
    "\n",
    "        for key in ranking.keys():\n",
    "            # 각 검색 시스템의 순위\n",
    "            embed_rank = ranking[key][0]\n",
    "            keyword_rank = ranking[key][1]\n",
    "\n",
    "            # 각 검색 시스템의 Reciprocal Rank 계산\n",
    "            embed_rr = self.reciprocal_rank(embed_rank)\n",
    "            keyword_rr = self.reciprocal_rank(keyword_rank)\n",
    "\n",
    "            # 가중치가 적용된 Reciprocal Rank 계산\n",
    "            rrf = (self.EMBED_WEIGHT * embed_rr) + (self.KEYWORD_WEIGHT * keyword_rr)\n",
    "\n",
    "            scores.append(rrf)\n",
    "            ids.append(key)\n",
    "\n",
    "        sorted_scores = sorted(scores, reverse=True)\n",
    "        sorted_ids = [key for _, key in sorted(zip(scores, ranking.keys()), reverse=True)]\n",
    "        return {\"ids\": sorted_ids, \"scores\": sorted_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1da79afd-306a-4365-8174-563694885ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf = RRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4374e2b2-01ac-45da-bb43-762f6a063bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>answer</th>\n",
       "      <th>class</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17520</th>\n",
       "      <td>선생님이 나한테 왜 그럴까?</td>\n",
       "      <td>선생님께 서운한 일이 있으셨나봐요.. 그래도 좋은 분이실테니 잘 지내시길 바랄게요</td>\n",
       "      <td>일상</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10593</th>\n",
       "      <td>네가 나한테 왜 그랬는지 아직도 이해가 안돼.</td>\n",
       "      <td>상대방의 행동으로 인해 상처를 받았군요. 남에게 상처를 주는 행동으로 하는 사람들의...</td>\n",
       "      <td>사연</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23831</th>\n",
       "      <td>왜 나한테만 이런일이 몰려올까</td>\n",
       "      <td>저도 비슷한 고민을 많이 해요. 생각이 많은 것보다 단순하게 사는 게 오히려 좋은 ...</td>\n",
       "      <td>사연</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user  \\\n",
       "17520            선생님이 나한테 왜 그럴까?   \n",
       "10593  네가 나한테 왜 그랬는지 아직도 이해가 안돼.   \n",
       "23831           왜 나한테만 이런일이 몰려올까   \n",
       "\n",
       "                                                  answer class  scores  \n",
       "17520      선생님께 서운한 일이 있으셨나봐요.. 그래도 좋은 분이실테니 잘 지내시길 바랄게요    일상     0.6  \n",
       "10593  상대방의 행동으로 인해 상처를 받았군요. 남에게 상처를 주는 행동으로 하는 사람들의...    사연     0.4  \n",
       "23831  저도 비슷한 고민을 많이 해요. 생각이 많은 것보다 단순하게 사는 게 오히려 좋은 ...    사연     0.3  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"왜 나한테만 그래?\"\n",
    "rerank = rrf.get_rrf_scores(reply(query).index.to_list() , bm25_chatbot_response(query).index.to_list())\n",
    "res_df = df.loc[rerank['ids']]\n",
    "res_df['scores'] = rerank['scores']\n",
    "res_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
